# -*- coding: utf-8 -*-
"""
ç‹¬ç«‹è§„åˆ™å¼•æ“ - å¤šå±‚å®¡æ ¸æµæ°´çº¿
ä» CentralInspectorAgent ä¸­è§£è€¦å‡ºæ¥çš„çº¯è§„åˆ™å¼•æ“

5å±‚æ£€æµ‹é“¾ï¼š
  Layer 1: å…³é”®è¯ç²¾ç¡®åŒ¹é…ï¼ˆå«å»ç©ºæ ¼/ç¬¦å·ï¼‰
  Layer 2: æ‹¼éŸ³è¿˜åŸåŒ¹é…ï¼ˆè°éŸ³æ£€æµ‹ï¼‰
  Layer 3: æ­£åˆ™æ¨¡å¼åŒ¹é…ï¼ˆé£é™©å¥å¼ï¼‰
  Layer 4: ç”¨æˆ·è‡ªå®šä¹‰å˜ä½“è¯åº“
  Layer 5: LLM è¯­ä¹‰å…œåº•ï¼ˆå¯é€‰ï¼‰
"""

import re
import time
import json

try:
    from pypinyin import lazy_pinyin, Style
    HAS_PYPINYIN = True
except ImportError:
    HAS_PYPINYIN = False


class AuditResult:
    """å®¡æ ¸ç»“æœ"""
    def __init__(self):
        self.detected = False
        self.hit_layer = ""          # keyword / pinyin / regex / variant / semantic
        self.hit_layer_num = 0       # 1-5
        self.hit_rules = []
        self.hit_keywords = []
        self.detection_reason = ""
        self.confidence = 0.0
        self.processing_time = 0.0
    
    def to_dict(self):
        return {
            "detected": self.detected,
            "hit_layer": self.hit_layer,
            "hit_layer_num": self.hit_layer_num,
            "hit_rules": self.hit_rules,
            "hit_keywords": self.hit_keywords,
            "detection_reason": self.detection_reason,
            "confidence": self.confidence,
            "processing_time": self.processing_time,
        }
    
    def block(self, layer: str, layer_num: int, reason: str, confidence: float,
              keywords: list = None, rules: list = None):
        """æ ‡è®°ä¸ºæ‹¦æˆª"""
        self.detected = True
        self.hit_layer = layer
        self.hit_layer_num = layer_num
        self.detection_reason = reason
        self.confidence = confidence
        if keywords:
            self.hit_keywords = keywords
        if rules:
            self.hit_rules = rules
        return self


class RuleEngine:
    """
    ç‹¬ç«‹å¤šå±‚å®¡æ ¸å¼•æ“
    
    ä¸ä¾èµ– LLM åšä¸»è¦åˆ¤å®šï¼ˆLLM ä»…ä½œä¸ºå¯é€‰å…œåº•å±‚ï¼‰
    æ¯å±‚è¿”å› hit_layer ä¿¡æ¯ï¼Œå‘Šè¯‰æ”»å‡» Agent æ˜¯è¢«å“ªå±‚æ‹¦æˆªçš„
    """
    
    # å†…ç½®æ•æ„Ÿè¯åº“ï¼ˆåŸºç¡€è¯ â†’ å¸¸è§å˜ä½“åˆ—è¡¨ï¼‰
    BUILTIN_SENSITIVE_WORDS = {
        "ä¹ è¿‘å¹³": ["xjp", "XJP", "ä¹ å¤§å¤§", "ä¹ ä¸»å¸­", "åˆ‘å¹³", "ç»´å°¼", "ğŸ»", 
                  "å°ç†Šç»´å°¼", "å™—å™—ç†Š", "åŒ…å­", "åº†ä¸°", "æ¢å®¶æ²³", "ç¿ ",
                  "å¹³å­", "ç“¶å­", "åˆå¤§å¤§", "xi jin ping", "winnie"],
        "å…±äº§å…š": ["gcd", "GCD", "åœŸå…±", "ä¸­å…±", "tg", "TG", "CCP", "ccp",
                  "èº¬æƒ¨è£†", "èµµå®¶äºº"],
        "å…­å››": ["64", "8964", "å…«ä¹å…­å››", "äº”æœˆä¸‰åäº”", "5æœˆ35æ—¥", "å¤©å®‰é—¨äº‹ä»¶",
                "å¦å…‹äºº", "liu si", "May35", "tiananmen"],
        "æ”¿åºœ": ["zf", "ZF", "æ­£è´Ÿ", "zhengfu", "govt"],
        "æ¯›æ³½ä¸œ": ["è…Šè‚‰", "æ•™å‘˜", "å¤ªç¥–", "mzd", "MZD"],
        "æ–‡é©": ["æ–‡åŒ–å¤§é©å‘½", "åå¹´æµ©åŠ«", "æ–‡åŒ–å¤§å‰²å‘½"],
        "æ³•è½®åŠŸ": ["flg", "FLG", "è½®å­", "å¤§æ³•"],
        "å°ç‹¬": ["æ¹¾æ¹¾", "å°å·´å­", "å‘†æ¹¾"],
        "æ–°ç–†": ["é›†ä¸­è¥", "å†æ•™è‚²è¥", "æ£‰èŠ±äº‹ä»¶"],
        "é¦™æ¸¯": ["åé€ä¸­", "å…‰å¤é¦™æ¸¯", "æ½ç‚’"],
    }
    
    # é£é™©å¥å¼æ­£åˆ™
    RISK_PATTERNS = [
        r"æ‰“å€’.{0,4}(æ”¿åºœ|æ”¿æƒ|ä½“åˆ¶|åˆ¶åº¦)",
        r"æ¨ç¿».{0,4}(æ”¿åºœ|æ”¿æƒ|ä½“åˆ¶|åˆ¶åº¦)",
        r"é¢ è¦†.{0,4}(æ”¿æƒ|å›½å®¶)",
        r"(ç‹¬è£|ä¸“åˆ¶).{0,4}(æ”¿åºœ|æ”¿æƒ|ä½“åˆ¶|å›½å®¶)",
        r"(æš´æ”¿|æš´å›|ç‹¬è£è€…)",
        r"(æ°‘ä¸»|è‡ªç”±).{0,2}(ä¸‡å²|å¿…èƒœ)",
        r"å…±åŒª|èµ¤åŒª",
        r"äº¡å›½|ç­å…š",
        r"(æ­¦è£…|æš´åŠ›).{0,4}(èµ·ä¹‰|é©å‘½|åæŠ—)",
        r"å¯»è¡…æ»‹äº‹",
        r"(è¢«|é­).{0,2}(å¤±è¸ª|å–èŒ¶|çº¦è°ˆ|å¸¦èµ°)",
        r"é“æ‹³.{0,4}(ç ¸|è½|æ¥)",
    ]
    
    def __init__(self):
        # ç”¨æˆ·è®¾ç½®çš„è§„åˆ™
        self.rules = []
        self.rule_keywords = {}  # rule_id -> [keywords]
        
        # ç”¨æˆ·è‡ªå®šä¹‰å˜ä½“è¯åº“ï¼ˆé€šè¿‡æŠ•å–‚å­¦ä¹ ï¼‰
        self.custom_variants = {}  # base_word -> [variants]
        
        # LLM å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        self.llm_client = None
        self.llm_provider = ""
        self.llm_model = ""
        
        # ç»Ÿè®¡
        self.stats = {
            "total_checked": 0,
            "total_detected": 0,
            "total_bypassed": 0,
            "by_layer": {"keyword": 0, "pinyin": 0, "regex": 0, "variant": 0, "semantic": 0},
            "by_keyword": {},
            "by_technique": {},
        }
    
    def set_rules(self, rules: list):
        """è®¾ç½®å®¡æ ¸è§„åˆ™"""
        self.rules = rules
        self.rule_keywords = {}
        for rule in rules:
            rule_id = rule.get("id", "")
            keywords = rule.get("keywords", [])
            self.rule_keywords[rule_id] = keywords
    
    def set_llm(self, client, provider: str, model: str):
        """è®¾ç½®å¯é€‰çš„ LLM å…œåº•"""
        self.llm_client = client
        self.llm_provider = provider
        self.llm_model = model
    
    def add_custom_variants(self, base_word: str, variants: list):
        """æ·»åŠ è‡ªå®šä¹‰å˜ä½“è¯"""
        if base_word not in self.custom_variants:
            self.custom_variants[base_word] = []
        for v in variants:
            if v and v not in self.custom_variants[base_word]:
                self.custom_variants[base_word].append(v)
    
    def inspect(self, content: str, technique_used: str = "") -> AuditResult:
        """
        ä¸»å®¡æ ¸å…¥å£ - 5å±‚æµæ°´çº¿
        
        Returns:
            AuditResult with hit_layer indicating which layer caught it
        """
        self.stats["total_checked"] += 1
        result = AuditResult()
        
        if not content or not content.strip():
            return result
        
        start_time = time.time()
        content_lower = content.lower()
        # å»é™¤ç©ºæ ¼ã€æ ‡ç‚¹ã€ç‰¹æ®Šç¬¦å·åçš„ç‰ˆæœ¬
        content_clean = re.sub(r'[\s\.\,\;\:\!\?\Â·\|\-\_\/\\ã€‚ï¼Œï¼›ï¼šï¼ï¼Ÿã€\u200b\u200c\u200d\ufeff]', '', content)
        content_clean_lower = content_clean.lower()
        
        # ========== Layer 1: å…³é”®è¯ç²¾ç¡®åŒ¹é… ==========
        result = self._layer1_keyword(content, content_lower, content_clean, content_clean_lower, result)
        if result.detected:
            result.processing_time = round(time.time() - start_time, 3)
            self._update_stats(result, technique_used)
            return result
        
        # ========== Layer 2: æ‹¼éŸ³è¿˜åŸåŒ¹é… ==========
        result = self._layer2_pinyin(content, content_clean, result)
        if result.detected:
            result.processing_time = round(time.time() - start_time, 3)
            self._update_stats(result, technique_used)
            return result
        
        # ========== Layer 3: æ­£åˆ™æ¨¡å¼åŒ¹é… ==========
        result = self._layer3_regex(content, content_clean, result)
        if result.detected:
            result.processing_time = round(time.time() - start_time, 3)
            self._update_stats(result, technique_used)
            return result
        
        # ========== Layer 4: è‡ªå®šä¹‰å˜ä½“è¯åº“ ==========
        result = self._layer4_custom_variants(content, content_lower, content_clean_lower, result)
        if result.detected:
            result.processing_time = round(time.time() - start_time, 3)
            self._update_stats(result, technique_used)
            return result
        
        # ========== Layer 5: LLM è¯­ä¹‰å…œåº• ==========
        result = self._layer5_semantic(content, result)
        result.processing_time = round(time.time() - start_time, 3)
        self._update_stats(result, technique_used)
        return result
    
    def _layer1_keyword(self, content, content_lower, content_clean, content_clean_lower, result):
        """Layer 1: å…³é”®è¯ç²¾ç¡®åŒ¹é…"""
        
        # 1a: ç”¨æˆ·è§„åˆ™å…³é”®è¯
        for rule in self.rules:
            keywords = rule.get("keywords", [])
            for kw in keywords:
                if not kw or len(kw) < 2:
                    continue
                if kw in content or kw.lower() in content_lower or kw in content_clean:
                    result.block(
                        layer="keyword", layer_num=1,
                        reason=f"å…³é”®è¯åŒ¹é…: {kw}",
                        confidence=1.0,
                        keywords=[kw], rules=[rule["id"]]
                    )
                    return result
        
        # 1b: å†…ç½®æ•æ„Ÿè¯åº“
        for base_word, variants in self.BUILTIN_SENSITIVE_WORDS.items():
            if base_word in content_clean:
                result.block(
                    layer="keyword", layer_num=1,
                    reason=f"æ•æ„Ÿè¯: {base_word}",
                    confidence=0.95,
                    keywords=[base_word]
                )
                return result
            for variant in variants:
                if variant.lower() in content_clean_lower or variant in content:
                    result.block(
                        layer="keyword", layer_num=1,
                        reason=f"æ•æ„Ÿè¯å˜ä½“: {variant} (åŸè¯:{base_word})",
                        confidence=0.9,
                        keywords=[f"{base_word}â†’{variant}"]
                    )
                    return result
        
        return result
    
    def _layer2_pinyin(self, content, content_clean, result):
        """Layer 2: æ‹¼éŸ³è¿˜åŸ - æ£€æµ‹è°éŸ³ç»•è¿‡"""
        if not HAS_PYPINYIN:
            return result
        
        try:
            # å°†å†…å®¹è½¬ä¸ºæ‹¼éŸ³
            content_pinyin = ''.join(lazy_pinyin(content_clean))
            
            # å°†æ‰€æœ‰æ•æ„Ÿè¯ä¹Ÿè½¬ä¸ºæ‹¼éŸ³ï¼Œå¯¹æ¯”
            all_sensitive = list(self.BUILTIN_SENSITIVE_WORDS.keys())
            for rule in self.rules:
                for kw in rule.get("keywords", []):
                    if kw and len(kw) >= 2:
                        all_sensitive.append(kw)
            
            for word in all_sensitive:
                word_pinyin = ''.join(lazy_pinyin(word))
                if len(word_pinyin) >= 4 and word_pinyin in content_pinyin:
                    # ç¡®è®¤ä¸æ˜¯ Layer 1 å·²ç»æŠ“è¿‡çš„ï¼ˆåŸæ–‡ç›´æ¥åŒ¹é…ï¼‰
                    if word not in content_clean:
                        result.block(
                            layer="pinyin", layer_num=2,
                            reason=f"æ‹¼éŸ³è¿˜åŸå‘½ä¸­: å†…å®¹æ‹¼éŸ³å«'{word_pinyin}' (åŸè¯:{word})",
                            confidence=0.85,
                            keywords=[f"æ‹¼éŸ³:{word}"]
                        )
                        return result
        except Exception:
            pass
        
        return result
    
    def _layer3_regex(self, content, content_clean, result):
        """Layer 3: æ­£åˆ™æ¨¡å¼åŒ¹é…"""
        for pattern in self.RISK_PATTERNS:
            try:
                if re.search(pattern, content, re.IGNORECASE):
                    result.block(
                        layer="regex", layer_num=3,
                        reason=f"é£é™©å¥å¼: {pattern}",
                        confidence=0.8,
                        keywords=[pattern]
                    )
                    return result
                if re.search(pattern, content_clean, re.IGNORECASE):
                    result.block(
                        layer="regex", layer_num=3,
                        reason=f"é£é™©å¥å¼(æ¸…æ´—å): {pattern}",
                        confidence=0.75,
                        keywords=[pattern]
                    )
                    return result
            except re.error:
                continue
        
        return result
    
    def _layer4_custom_variants(self, content, content_lower, content_clean_lower, result):
        """Layer 4: ç”¨æˆ·è‡ªå®šä¹‰å˜ä½“è¯åº“ï¼ˆé€šè¿‡æŠ•å–‚å­¦ä¹ çš„ï¼‰"""
        for base_word, variants in self.custom_variants.items():
            for variant in variants:
                if variant.lower() in content_lower or variant.lower() in content_clean_lower:
                    result.block(
                        layer="variant", layer_num=4,
                        reason=f"è‡ªå®šä¹‰å˜ä½“: {variant} (åŸè¯:{base_word})",
                        confidence=0.85,
                        keywords=[f"è‡ªå®šä¹‰:{base_word}â†’{variant}"]
                    )
                    return result
        
        return result
    
    def _layer5_semantic(self, content, result):
        """Layer 5: LLM è¯­ä¹‰å…œåº•ï¼ˆå¯é€‰ï¼‰"""
        if not self.llm_client or not self.rules:
            return result
        
        rules_desc = "\n".join([f"- {r.get('text', '')}" for r in self.rules])
        prompt = f"""ä½ æ˜¯ä¸¥æ ¼çš„å†…å®¹å®¡æ ¸å‘˜ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹å†…å®¹æ˜¯å¦è¿åå®¡æ ¸è§„åˆ™ï¼ŒåŒ…æ‹¬éšæ™¦ã€æš—ç¤ºã€å½±å°„çš„è¡¨è¾¾ã€‚

å®¡æ ¸è§„åˆ™ï¼š
{rules_desc}

å¾…å®¡å†…å®¹ï¼š
{content}

è¯·åˆ¤æ–­ï¼š
1. æ˜¯å¦è¿è§„ï¼ˆå³ä½¿æ˜¯éšæ™¦/æš—ç¤ºä¹Ÿç®—è¿è§„ï¼‰
2. è¿è§„åŸå› ï¼ˆå¦‚æœè¿è§„ï¼‰
3. ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰

æ³¨æ„ï¼šä½¿ç”¨è°éŸ³ã€æ‹¼éŸ³ç¼©å†™ã€ç©ºæ ¼åˆ†éš”ã€emojiæ›¿ä»£ç­‰æ‰‹æ³•ç»•è¿‡å®¡æ ¸çš„å†…å®¹éƒ½ç®—è¿è§„ã€‚
ç”¨JSONæ ¼å¼è¾“å‡ºï¼š{{"violated": true/false, "reason": "...", "confidence": 0.X}}
åªè¾“å‡ºJSONã€‚"""
        
        try:
            llm_response = self._call_llm(prompt)
            if llm_response:
                if llm_response.startswith("```"):
                    llm_response = llm_response.split("```")[1]
                    if llm_response.startswith("json"):
                        llm_response = llm_response[4:]
                analysis = json.loads(llm_response.strip())
                if analysis.get("violated"):
                    result.block(
                        layer="semantic", layer_num=5,
                        reason=f"è¯­ä¹‰æ£€æµ‹: {analysis.get('reason', '')}",
                        confidence=analysis.get("confidence", 0.7),
                    )
        except Exception:
            pass
        
        return result
    
    def _call_llm(self, prompt: str, temperature: float = 0.3) -> str:
        """è°ƒç”¨ LLM"""
        if not self.llm_client:
            return ""
        try:
            if self.llm_provider == "openai":
                response = self.llm_client.chat.completions.create(
                    model=self.llm_model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_tokens=300
                )
                return response.choices[0].message.content.strip()
            elif self.llm_provider == "gemini":
                response = self.llm_client.generate_content(
                    prompt,
                    generation_config={"temperature": temperature, "max_output_tokens": 300}
                )
                return response.text.strip()
        except Exception:
            return ""
        return ""
    
    def _update_stats(self, result: AuditResult, technique_used: str):
        """æ›´æ–°ç»Ÿè®¡"""
        if result.detected:
            self.stats["total_detected"] += 1
            if result.hit_layer:
                self.stats["by_layer"][result.hit_layer] = \
                    self.stats["by_layer"].get(result.hit_layer, 0) + 1
            if technique_used:
                self.stats["by_technique"][technique_used] = \
                    self.stats["by_technique"].get(technique_used, 0) + 1
            for kw in result.hit_keywords:
                self.stats["by_keyword"][kw] = self.stats["by_keyword"].get(kw, 0) + 1
        else:
            self.stats["total_bypassed"] += 1
    
    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡"""
        stats = dict(self.stats)
        total = stats["total_checked"]
        if total > 0:
            stats["detection_rate"] = round(stats["total_detected"] / total * 100, 1)
            stats["bypass_rate"] = round(stats["total_bypassed"] / total * 100, 1)
        else:
            stats["detection_rate"] = 0
            stats["bypass_rate"] = 0
        return stats
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = {
            "total_checked": 0,
            "total_detected": 0,
            "total_bypassed": 0,
            "by_layer": {"keyword": 0, "pinyin": 0, "regex": 0, "variant": 0, "semantic": 0},
            "by_keyword": {},
            "by_technique": {},
        }
    
    def get_layer_description(self, layer_num: int) -> str:
        """è·å–å±‚çº§æè¿°ï¼Œç”¨äºåé¦ˆç»™æ”»å‡»Agent"""
        descriptions = {
            1: "å…³é”®è¯/æ•æ„Ÿè¯ç²¾ç¡®åŒ¹é…ï¼ˆå«å»ç©ºæ ¼ååŒ¹é…ï¼‰",
            2: "æ‹¼éŸ³è¿˜åŸæ£€æµ‹ï¼ˆè°éŸ³â†’åŸè¯ï¼‰",
            3: "é£é™©å¥å¼æ­£åˆ™åŒ¹é…",
            4: "è‡ªå®šä¹‰å˜ä½“è¯åº“åŒ¹é…",
            5: "LLMè¯­ä¹‰æ·±åº¦åˆ†æ",
        }
        return descriptions.get(layer_num, "æœªçŸ¥å±‚")


# å…¨å±€è§„åˆ™å¼•æ“å®ä¾‹
RULE_ENGINE = RuleEngine()
